{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import imageio\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def plotGrayImage(data):\n",
    "    plt.imshow(data, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\n",
    "    plt.show()\n",
    "\n",
    "def cropImage(im, size):\n",
    "    \"\"\"This function crops the center of the image with the size specified by user\"\"\"\n",
    "    x, y = im.shape\n",
    "    middleX = round(x / 2)\n",
    "    middleY = round(y / 2)\n",
    "    margin = int((size / 2))\n",
    "    return im[middleX - margin:middleX + margin,middleX - margin:middleX + margin]\n",
    "\n",
    "def addBorderZeroPaddToImage(im, extraBorderWidth):\n",
    "    \"\"\"This function creates a zero padding to the image, the width of the border is related with the parameter \n",
    "    extraBorderWidth\"\"\"\n",
    "    return np.pad(im, extraBorderWidth, 'constant', constant_values=0)\n",
    "\n",
    "def resizeImage(im, size):\n",
    "    \"\"\"This normalize the image to the size specified, it simply make the image bigger with zeros and then crop the\n",
    "    image to the size declared by user\"\"\"\n",
    "    return cropImage(addBorderZeroPaddToImage(im, size),size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(numSamples=100):\n",
    "    # `cwd`: current directory is straightforward\n",
    "    cwd = Path.cwd()\n",
    "\n",
    "    parasitizedPath = str(cwd) + \"/cell_images/Parasitized\"\n",
    "    uninfectedPath = str(cwd) + \"/cell_images/Uninfected\"\n",
    "    \n",
    "    parasitedPaths = []\n",
    "    paraFiles = []\n",
    "    for file in os.listdir(parasitizedPath)[0:numSamples]:\n",
    "        if os.path.isfile(os.path.join(parasitizedPath, file)):\n",
    "            if file.endswith(\".png\"):\n",
    "                temp = parasitizedPath + \"/\" + file\n",
    "                gray = rgb2gray(imageio.imread(temp))\n",
    "                parasitedPaths.append(temp)\n",
    "                paraFiles.append(gray)\n",
    "\n",
    "    uninfectedPaths = []\n",
    "    uninFiles = []\n",
    "\n",
    "    for file in os.listdir(uninfectedPath)[0:numSamples]:\n",
    "        if os.path.isfile(os.path.join(uninfectedPath, file)):\n",
    "            if file.endswith(\".png\"):\n",
    "                temp = uninfectedPath + \"/\" + file\n",
    "                gray = rgb2gray(imageio.imread(temp))\n",
    "                uninfectedPaths.append(temp)\n",
    "                uninFiles.append(gray)\n",
    "    \"\"\"Until now I have all paths with images files and their data. \n",
    "        The data is already classified as parasited and uninfected\n",
    "\n",
    "        I want to make one dataframe to gather all information.  \n",
    "        The dataframe will have the following columns\n",
    "\n",
    "        * status: It tells if the sample is parasited or uninfected\n",
    "        * pathfile: it is self-explanatory\n",
    "        * data: the image data\"\"\"            \n",
    "    \n",
    "    status = np.concatenate((np.ones(len(parasitedPaths)),np.zeros(len(uninfectedPaths))))\n",
    "    pathfile = parasitedPaths + uninfectedPaths\n",
    "    data = np.concatenate((paraFiles, uninFiles))\n",
    "    return pd.DataFrame({\"pathfile\": pathfile, \"data\": data, \"status\": status})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = getData(500)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Just to see one image as a manner of example:\n",
    "plotGrayImage(df[\"data\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since I have notice that images have different dimmensions, I need to make them the same size.\n",
    "But first I am goint be find the biggest one and make the rest the same size with zero values in the edges. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxSize = np.array([x.shape for x in df[\"data\"]]).flatten().max()\n",
    "maxSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = df[\"data\"][0]\n",
    "result = addBorderZeroPaddToImage(t, maxSize)\n",
    "plotGrayImage(t)\n",
    "plotGrayImage(result)\n",
    "r = cropImage(result, maxSize)\n",
    "plotGrayImage(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_validation, df_test = train_test_split(df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjusting size of database images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorImages = pd.DataFrame(df_train_validation[\"data\"].apply(lambda x: resizeImage(x, maxSize).ravel()).values.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorImages_train, vectorImages_test, labels_train, labels_test = train_test_split(vectorImages, df_train_validation[\"status\"], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(vectorImages_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(vectorImages_test, labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the accuracy is barely better than a flip a coin estimator, I have to change the strategy to improve the model. \n",
    "\n",
    "The current model does such a horrible job because the observable pattern (the one that has to be enclosed or segmented\n",
    "by the classifier) is in different dimmensions in each sample so the the optimization algorithm does not where to go\n",
    "in order to truly fit the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processToHistVectorImages(x, maxSize):\n",
    "    vector = resizeImage(x, maxSize).ravel()\n",
    "    return list(np.histogram(vector,bins=40)[0])[1:]\n",
    "\n",
    "histVectorImages = pd.DataFrame(df_train_validation[\"data\"].apply(lambda x: processToHistVectorImages(x, maxSize)).values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"histVectors\"] = df_test[\"data\"].apply(lambda x: processToHistVectorImages(x, maxSize)).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histVectorImages_train, histVectorImages_test, labels_train, labels_test = train_test_split(histVectorImages, df_train_validation[\"status\"], test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histModel = LogisticRegression()\n",
    "histModel.fit(histVectorImages_train, labels_train)\n",
    "#histModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histModel.score(histVectorImages_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for index in range(len(df_test)):\n",
    "#     predict = histModel.predict(np.array(df_test[\"histVectors\"].iloc[index]).reshape(1,-1))\n",
    "#     print(\"True value: \" , df_test[\"status\"].iloc[index])\n",
    "#     print(\"  Predicted: \", predict)\n",
    "#     plotGrayImage(df_test[\"data\"].iloc[index])\n",
    "#     print(\"-------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
